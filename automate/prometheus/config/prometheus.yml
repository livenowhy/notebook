# my global config
# 全局配置
global:
  scrape_interval:     10s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  scrape_timeout:      10s # scrape_timeout is set to the global default (10s).
  # scrape_interval:     抓取间隔
  # evaluation_interval: 评估规则间隔
  # scrape_timeout:      抓取超时时间

  # 当 Prometheus 和外部系统(远程存储, Alertmanager)通信的时候,添加标签到任意的时间序列或者报警
  # (加上之后查询 prometheus 时sql语句被加上相应标签，导致无法查询到数据)
#  external_labels:
#    cluster: prometheus-dev
#    datasource: node_exporter

# Alertmanager configuration; Alertmanager相关的配置
alerting:
  alertmanagers:
  - static_configs:
    - targets:
       - corevm.livenowhy.com:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
# 规则文件, 可以使用通配符
rule_files:
   - "rules.yml"
  # - "rules/*rules.yml"


# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
# 收集数据配置列表
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'  # 必须配置, 自动附加的job labels, 必须唯一
    # 可以在定义局部的 scrape_interval、scrape_timeout, 默认继承global值
    # sample_limit: 1000  # 每次收集样本数据的限制. 0 为不限制
    # metrics_path defaults to '/metrics'  # 抓取路径, 默认是/metrics
    # scheme defaults to 'http'.           # 指定采集使用的协议, http或者https
    # params: 指定 url 参数
    # basic_auth: 指定认证信息
    # *_sd_configs: 指定服务发现配置
    # static_configs: 静态指定服务 job
    # relabel_config: relabel 设置

    static_configs:
    - targets: ['localhost:9090']

  - job_name: 'node_exporter'
    static_configs:
    - targets: ['corevm.livenowhy.com:9100']
      labels:
        appname: 'node_exporter'

  - job_name: 'huaweimetrics'
    # 标签冲突, true 为以抓取的数据为准并忽略服务器中的; false 为通过重命名来解决冲突
    honor_labels: true
    metrics_path: '/app/metrics/metrics'
    static_configs:
    - targets: ['corevm.livenowhy.com:8088']
      labels:
        appname: 'huaweimetrics'
    metric_relabel_configs:
      - regex: 'appname'
        action: labeldrop
      - regex: 'job'
        action: labeldrop
      - regex: 'instance'
        action: labeldrop
# 数据收集支持, basic_auth: HTTP basic 认证信息; 数据源中可以配置认证信息

remote_write:
  - url: "http://corevm.livenowhy.com:9201/write"

remote_read:
  - url: "http://corevm.livenowhy.com:9201/read"

# remote_write、remote_read 配置远端存储
# 长期存储 prometheus 的监控数据，可以选择 influxdb 作为 remote storage
# 远程写入功能相关的设置; 指定后端的存储的写入api地址
#remote_write:
#  - url: http://remote1/push
#    write_relabel_configs:
#    - source_labels: [__name__]
#      regex:         expensive.*
#      action:        drop

# 远程读取相关功能的设置; 指定后端的存储的读取api地址
#remote_read:
#  - url: http://remote3/read
#    read_recent: false
#    required_matchers:
#      job: special


# https://www.cnblogs.com/momoyan/p/11783519.html

# 还可以配置如下:
# 1、consul 服务发现配置列表
# 2、文件服务发现配置列表

# 目标节点重新打标签的配置列表.
# 重新标记是一个功能强大的工具，可以在抓取目标之前动态重写目标的标签集。
# 可以配置多个，按照先后顺序应用
#relabel_configs:
#- source_labels: [job, __meta_dns_name]   # 从现有的标签中选择源标签, 最后会被 替换， 保持， 丢弃
#  regex:         (.*)some-[regex]  # 正则表达式, 将会提取source_labels中匹配的值
#  target_label:  job   # 在替换动作中将结果值写入的标签.
#  replacement:   foo-${1}  # 如果正则表达匹配, 那么替换值. 可以使用正则表达中的 捕获组
#  # action defaults to 'replace'